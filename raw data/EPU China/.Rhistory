1-0.44
107.5*0.44
537.5-344
107.5/193.5
0.56*344
0.56*430-192.64
107.5*0.44
0.5555*344
0.555555*430-191.092
0.5555555*344
0.5555556*344
0.5555556*430-191.1111
20/45
0.4444444*107.5
100/150
0.67/2
1/1.10
0.67*50
33.5*0.909
67-30.45
60/150
40/1.1
0.06^2
3^0.5
1.732051*0.06
0.0118*3/0.1039
0.341-0.06*3^0.5
pnorm(0.237077)
pnorm(0.341)
60*0.633+60*exp(-0.03)*0.5937
60*0.633-60*exp(-0.03)*0.5937
3.41+60*exp(-0.03)-60
3.41-60
1.637-60
48-33.32
-8/14.68
2^0.5/2
0.7071068*0.25
exp(0.1767767)
1/1.193
1-0.838
45*1.193
45*0.838
53.69*1,193
53.69*1.193
53.69*0.838
37.71*1.193
37.71*0.838
e^1
exp(0.24*0.25^0.5)
1/1.127
45*1.127
110*0.33
56.3/0.33
1/0.33
170.61*1.10
110*0.33
220-55
165/55
55/1.10
165*0.6/1.1
110*0.6/1.1
90*0.6/1.1
exp(0.24*(0.5^0.5))
440-25
110-25
415*2
415/2
85*2
85/2
830-165
207.5-165
665*0.4+42.5*0.6
291.5/1.1
440-165
5*0.4
2/1.1
275*0.4+1.82*0.6
111.09/1.1
1.21^0.5
pnorm(1.5333)
pnorm(1.31)
200*0.937-180*exp(-0.21)*0.9
exp(0.223)
1/1.249
exp(0.223*0.5^0.5)
1/1.171
20-36-110
2972-2386
586/2972
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
install.packages("rugarch")
library(dynlm)
library(TSA)
library(rugarch)
install.packages("dynlm")
install.packages("TSA")
install.packages("~/Downloads/TSA_1.2.1.tar.gz", repos = NULL, type = "source")
adlm_4
df = read_excel("finret.xlsx")
library(dynlm)
library(TSA)
library(rugarch)
library(car)
library(tseries)
library(car)
library(readxl)
library(vars)
library(lmtest)
library(AER)
library(dynlm)
library(forecast)
library(car)
library(FinTS)
library(fpp)
shccm <- function(model, type=c("hc0", "hc1", "hc2", "hc3", "hc4")){
# R-code (www.r-project.org) for computing
# HC standard errors for a linear model (lm).
# > source("http://thiloklein.de/R/myfunctions.R")
# The arguments of the function are:
# model = a model fitted with lm()
# type  = one of "hc0" to "hc4", refer to package hccm in the car library for a description
# Example: shccm(my.lm.model, "hc0")
if (!require(car)) stop("Required car package is missing.")
type <- match.arg(type)
V <- hccm(model, type=type)
sumry <- summary(model)
table <- coef(sumry)
table[,2] <- sqrt(diag(V))
table[,3] <- table[,1]/table[,2]
table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
sumry$coefficients <- table
p <- nrow(table)
hyp <- if (names(model$coef)[1]=="(Intercept)") cbind(0, diag(p - 1))
else diag(p)
sumry$fstatistic[1] <- linearHypothesis(model, hyp, white.adjust=type)[2,"F"]
print(sumry)
cat("Note: Heteroscedasticity-consistent standard errors
using adjustment", type, "\n")
}
shaccm <- function(model){
# R-code (www.r-project.org) for computing
# HAC standard errors for a linear model (lm).
# The arguments of the function are:
# model = a model fitted with lm()
# Example: shaccm(my.linear.model)
if (!require(sandwich)) stop("Required sandwich package is missing.")
V <- vcovHAC(model)
sumry <- summary(model)
table <- coef(sumry)
table[,2] <- sqrt(diag(V))
table[,3] <- table[,1]/table[,2]
table[,4] <- 2*pt(abs(table[,3]), df.residual(model), lower.tail=FALSE)
sumry$coefficients <- table
p <- nrow(table)
hyp <- if (names(model$coef)[1]=="(Intercept)") cbind(0, diag(p - 1)) else diag(p)
sumry$fstatistic[1] <- linearHypothesis(model, hyp, vcov.=vcovHAC)[2,"F"]
print(sumry)
cat("Note: Heteroscedasticity and autocorrelation consistent standard errors", "\n")
}
## ===========================================
## Convenience Functions to carry out ADF test
## ===========================================
# --- Augmented Dickey Fuller test (correct p-value) ---
adf.test.1<-function (x, int, trend, k = trunc((length(x)- 1)^(1/3))){
# R-code (www.r-project.org) for computing an
# Augmented Dickey Fuller test.
# Thanks to Thilo Klein
# The arguments of the function are as in the original adf.test function, i.e.
# x    = a numeric vector or time series
# k    = the lag order to calculate the test statistic.
# In addition, we have
# int   = logical, a constant is included if int=T
# trend = logical, a trend variable is included if trend=T
# Example: adf.test.1(my.time.series, int=F, trend=T)
# The null is ALWAYS non stationarity.
if (NCOL(x) > 1)
stop("x is not a vector or univariate time series")
if (any(is.na(x)))
stop("NAs in x")
if (k < 0)
stop("k negative")
DNAME <- deparse(substitute(x))
k <- k + 1
y <- diff(x)
n <- length(y)
z <- embed(y, k)
yt <- z[,1]
xt1 <- x[k:n]
tt <- k:n
if (int==F & trend==F){
table <- cbind(c(2.66, 2.62, 2.6, 2.58, 2.58, 2.58),
c(2.26, 2.25, 2.24, 2.23, 2.23, 2.23),
c(1.95, 1.95, 1.95, 1.95, 1.95, 1.95),
c(1.60, 1.61, 1.61, 1.62, 1.62, 1.62),
c(0.92, 0.91, 0.90, 0.89, 0.89, 0.89),
c(1.33, 1.31, 1.29, 1.29, 1.28, 1.28),
c(1.70, 1.66, 1.64, 1.63, 1.62, 1.62),
c(2.16, 2.08, 2.03, 2.01, 2.00, 2.00))
if (k > 1) {
yt1 <- z[,2:k]
res <- lm(yt ~ xt1 - 1 + yt1)
}
else res <- lm(yt ~ xt1-1)
res.sum <- summary(res)
STAT <- res.sum$coefficients[1,1]/res.sum$coefficients[1,2]
}
if (int==T & trend==F){
table <- cbind(c(3.75, 3.58, 3.51, 3.46, 3.44, 3.43),
c(3.33, 3.22, 3.17, 3.14, 3.13, 3.12),
c(3.00, 2.93, 2.89, 2.88, 2.87, 2.86),
c(2.62, 2.60, 2.58, 2.57, 2.57, 2.57),
c(0.37, 0.40, 0.42, 0.42, 0.43, 0.44),
c(0.00, 0.03, 0.05, 0.06, 0.07, 0.07),
c(0.34, 0.29, 0.26, 0.24, 0.24, 0.23),
c(0.72, 0.66, 0.63, 0.62, 0.61, 0.60))
if (k > 1) {
yt1 <- z[,2:k]
res <- lm(yt ~ xt1 + 1 + yt1)
}
else res <- lm(yt ~ xt1 + 1)
res.sum <- summary(res)
STAT <- res.sum$coefficients[2,1]/res.sum$coefficients[2,2]
}
if (int==T & trend==T){
table <- cbind(c(4.38, 4.15, 4.04, 3.99, 3.98, 3.96),
c(3.95, 3.8,  3.73, 3.69, 3.68, 3.66),
c(3.6,  3.5,  3.45, 3.43, 3.42, 3.41),
c(3.24, 3.18, 3.15, 3.13, 3.13, 3.12),
c(1.14, 1.19, 1.22, 1.23, 1.24, 1.25),
c(0.8,  0.87, 0.9,  0.92, 0.93, 0.94),
c(0.5,  0.58, 0.62, 0.64, 0.65, 0.66),
c(0.15, 0.24, 0.28, 0.31, 0.32, 0.33))
if (k > 1) {
yt1 <- z[,2:k]
res <- lm(yt ~ xt1 + 1 + tt + yt1)
}
else res <- lm(yt ~ xt1 + 1 + tt)
res.sum <- summary(res)
STAT <- res.sum$coefficients[2,1]/res.sum$coefficients[2,2]
}
table <- -table
tablen <- dim(table)[2]
tableT <- c(25, 50, 100, 250, 500, 1e+05)
tablep <- c(0.01, 0.025, 0.05, 0.1, 0.9, 0.95, 0.975, 0.99)
tableipl <- numeric(tablen)
for (i in (1:tablen)) tableipl[i] <- approx(tableT, table[,i], n, rule = 2)$y
interpol <- approx(tableipl, tablep, STAT, rule = 2)$y
if (is.na(approx(tableipl, tablep, STAT, rule = 1)$y))
if (interpol == min(tablep))
warning("p-value smaller than printed p-value")
else warning("p-value greater than printed p-value")
PVAL <- interpol
PARAMETER <- k - 1
METHOD <- "Augmented Dickey-Fuller Test"
names(STAT) <- "Dickey-Fuller"
names(PARAMETER) <- "Lag order"
structure(list(statistic = STAT, parameter = PARAMETER,alternative = "The series has no unit root",
p.value = PVAL, method = METHOD, data.name = DNAME),class = "htest")
}
# ----------------------------------------------
# --- Augmented Dickey Fuller test (summary) ---
adf.test.2 <- function(x, int = T, trend = T, k = trunc((length(x)- 1)^(1/3))){
# Construct Data for Augmented Dickey Fuller Model with k lags.
# R-code (www.r-project.org) for computing an
# Augmented Dickey Fuller test with k lags.
# Correct p-values need to be obtained from a Dickey-Fuller table!
# Thanks to Thilo Klein
# The arguments of the function are:
# x     = time series vector
# k     = number of lags to be included in the test
# int   = logical, a constant is included if int=t
# trend = logical, a trend variable is included if trend=T
# a) Models with intercept and trend (int=T, trend=T)
# b) Models with intercept but without trend (int=T, trend=F)
# c) Models without intercept and without trend (int=F, trend=F)
# Example: adf.test.2(my.time.series, k=2, int=T, trend=T)
x <- ts(x)   # convert the data x into time series
D <- diff(x) # compute the first difference of data x
if(k > 0) {
for(i in 1:k)
D <- ts.intersect(D, lag(diff(x),  - i))
}
D <- ts.intersect(lag(x, -1), D) # binds series exclude NAs
if(trend == T)
D <- ts.intersect(D, time(x))
y <- D[, 2]
x <- D[, -2]
if(int == T)
o2=lm(y ~ x)
else o2=lm(y ~ x - 1)
# if no intercept wanted then force regr thru origin using the -1
# list(o1=cbind(y,x), o2=o2)           # there are two outputs
o2
}
# ---------------------------------------------------
# --- F-test with Dickey-Fuller corrected p-value ---
linearHypothesis.adf <- function(model, hypothesis){
# R-code (www.r-project.org) for conducting a
# F-test with ADF corrected p-value.
# Thanks to Thilo Klein
# The arguments of the function are as in the original linearHypothesis function, i.e.
# model       = fitted model object
# hypothesis  = a character vector giving the hypothesis in symbolic form
# Example: linearHypothesis.adf(mymodel, c("xD.lag(x, -1)", "xtime(x)", "(Intercept)"))
if (!require(car)) stop("Required car package is missing.")
STAT <- lht(model, hypothesis)$F[2]
names(STAT) <- "F-statistic"
n <- length(model$resid)
if("(Intercept)" %in% hypothesis  &  "xtime(x)" %in% hypothesis == F){
table <- cbind(c(4.12, 3.94, 3.86, 3.81, 3.79, 3.78), #phi1
c(5.18, 4.86, 4.71, 4.63, 4.61, 4.59),
c(6.30, 5.80, 5.57, 5.45, 5.41, 5.38),
c(7.88, 7.06, 6.70, 6.52, 6.47, 6.43))
}
if("(Intercept)" %in% hypothesis  &  "xtime(x)" %in% hypothesis){
table <- cbind(c(4.67, 4.31, 4.16, 4.07, 4.05, 4.03), #phi2
c(5.68, 5.13, 4.88, 4.75, 4.71, 4.68),
c(6.75, 5.94, 5.59, 5.40, 5.35, 5.31),
c(8.21, 7.02, 6.50, 6.22, 6.15, 6.09))
}
if("(Intercept)" %in% hypothesis == F  &  "xtime(x)" %in% hypothesis){
table <- cbind(c(5.91, 5.61, 5.47, 5.39, 5.36, 5.34), #phi3
c(7.24, 6.73, 6.49, 6.34, 6.30, 6.25),
c(8.65, 7.81, 7.44, 7.25, 7.20, 7.16),
c(10.61, 9.31, 8.73, 8.43, 8.34, 8.27))
}
tablen <- dim(table)[2]
tableT <- c(25, 50, 100, 250, 500, 1e+05)
tablep <- c(0.1, 0.05, 0.025, 0.01)
tableipl <- numeric(tablen)
for (i in (1:tablen)) tableipl[i] <- approx(tableT, table[,i], n, rule = 2)$y
interpol <- approx(tableipl, tablep, STAT, rule = 2)$y
if (is.na(approx(tableipl, tablep, STAT, rule = 1)$y)){
if (interpol == min(tablep)){
warning("p-value smaller than printed p-value")
}
else{
warning("p-value greater than printed p-value")
}
}
structure(list(statistic = STAT, alternative = "a0/a2 and gamma jointly significant",
p.value = interpol, method="F-test with p-value from DF-table",data.name="ADF regression model"),class = "htest")
}
# ---------------------------------------------------
# --- Ljung-Box Test statistic with flexible lags ---
ljung.box.test.1 <- function (x, lags){
# Performs the Ljung-Box Test with flexible specification of lags.
# R-code (www.r-project.org) for computing the
# Ljung-Box Test statistic.
# > source("http://thiloklein.de/R/myfunctions.R")
# The arguments of the function are:
# x     = a vector of variables to be tested
# lags  = the lags for which test statistic and p-value should be reported
# Example: ljung.box.test.1(x = myvector, lags = seq(from=1,to=10,by=1))
if (!is.vector(x)) {
cat("Error: The argument must be a vector.\n")
}
else {
nobs <- length(x)
nlag <- seq(1, 50, 1)
y <- x - mean(x)
denom <- sum(y^2)
rho <- numeric(length(nlag))
for (i in 1:length(nlag)) {
rho[i] <- sum(y[(nlag[i] + 1):nobs] * y[1:(nobs -
nlag[i])])/denom
}
rho <- nobs * (nobs + 2) * (rho^2/(nobs - nlag))
Q <- cumsum(rho)
p.val <- pchisq(Q, df = nlag, lower.tail = FALSE)
ans <- cbind(Q, p.val)
colnames(ans) <- c("test stat", "p-value")
rownames(ans) <- paste("Lag", nlag)
ans[lags, ]
}
}
arima.select <- function(model) {
output <- rep(NA, 8)
names(output) <- c("AIC","SSR","Q(4)","Q(8)","Q(12)","pQ(4)","pQ(8)","pQ(12)")
output[1] <- model$aic
output[2] <- sum(model$res^2, na.rm=T)
tmp <- model$res ; nNA <- is.na(tmp)==F
output[3:5] <- ljung.box.test.1(tmp[nNA],seq(4,12,4))[,1]
output[6:8] <- ljung.box.test.1(tmp[nNA],seq(4,12,4))[,2]
output
}
maroots <- function(object)
{
if(!("Arima" %in% class(object)))
stop("object must be of class Arima")
parvec <- object$model$theta
if(length(parvec) > 0)
{
last.nonzero <- max(which(abs(parvec) > 1e-08))
if (last.nonzero > 0)
return(structure(list(
roots=polyroot(c(1,parvec[1:last.nonzero])),
type="MA"),
class='armaroots'))
}
return(structure(list(roots=numeric(0), type="MA"),
class='armaroots'))
}
df = read_excel("finret.xlsx")
rm_ts = ts(df$rm,frequency=12)
adf.test.1(rm_ts,int=TRUE,trend=TRUE,k=order)
ar(rm_ts)
adf.test.1(rm_ts,int=TRUE,trend=TRUE,k=6)
kpss.test(rm_ts."level")
kpss.test(rm_ts,"level")
kpss.test(rm_ts,"Level")
kpss.test(rm_ts,"Trend")
pp.test(rm_ts,"Trend")
pp.test(rm_ts,type=c("Z(t_alpha)"))
pp.test(rm_ts,type=c("Z(alpha)"))
install.packages("RPostgres")
library(RPostgres)
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
dbname='wrds',
sslmode='require',
user='wrds_username')
？dbConnect
?dbConnect
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
dbname='wrds',
sslmode='require',
user='mphfin08'，
password＝"Fincl19k")
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
dbname='wrds',
sslmode='require',
user='mphfin08',
password＝"Fincl19k")
wrds <- dbConnect(Postgres(),
host='wrds-pgdata.wharton.upenn.edu',
port=9737,
dbname='wrds',
sslmode='require',
user='mphfin08',
password="Fincl19k")
res <- dbSendQuery(wrds, "select * from crsp.dsf")
data <- dbFetch(res, n=10)
dbClearResult(res)
data
load("/Users/sunnyyang/Downloads/activateProgramsTAQ (2).RData")
df = .show_cq1day(100)
View(df)
setwd("~/Desktop/Impact of Goverment on Financial market/EPU China")
df = read.csv("data/sz50_2015_crisis.csv")
View(df)
stock_df = read.csv("data/sz50_2015_crisis.csv")
stock_df = read.csv("data/sz50_2015_crisis.csv")
epu_df = read.csv("china_epu_index_aggregate.csv")
epu_df = read.csv("data/china_epu_index_aggregate.csv")
View(epu_df)
View(epu_df)
?merge
View(stock_df)
View(stock_df)
merge(stock_df,epu_df,by="X")
df = read.csv("data/crisis_ret_epu.csv")
colnames(df)
lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal+df$CN_Monetary+df$CN_Trade+df$CN_EXR)
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal+df$CN_Monetary+df$CN_Trade+df$CN_EXR)
summary(mod1)
linearHypothesis(mod1,c("df$CNEPU","df$CN_Fiscal"),white.adjust = "hc0")
library(car)
library(AER)
library(QuantPsyc)
library(timeDate)
library(readxl)
library(lmtest)
library(tseries)
library(sfsmisc)
library(sandwich)
linearHypothesis(mod1,c("df$CNEPU","df$CN_Fiscal"),white.adjust = "hc0")
summary(mod1)
linearHypothesis(mod1,c("df$CN_Fiscal","df$CN_Monetary","df$CN_Trade","df$CN_EXR"),white.adjust = "hc0")
linearHypothesis(mod1,c("df$CN_Fiscal","df$CN_Monetary","df$CN_Trade","df$CN_EXR"))
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal+df$CN_Monetary+df$CN_Trade+df$CN_EXR)
summary(mod1)
linearHypothesis(mod1,c("df$CNEPU","df$CN_Fiscal","df$CN_Monetary","df$CN_Trade","df$CN_EXR")white.adjust = "hc0")
linearHypothesis(mod1,c("df$CNEPU","df$CN_Fiscal","df$CN_Monetary","df$CN_Trade","df$CN_EXR"),white.adjust = "hc0")
linearHypothesis(mod1,c("df$CN_Fiscal","df$CN_Monetary","df$CN_Trade","df$CN_EXR"),white.adjust = "hc0")
linearHypothesis(mod1,c("df$CN_Fiscal","df$CN_Monetary","df$CN_Trade"),white.adjust = "hc0")
linearHypothesis(mod1,c("df$CN_Fiscal","df$CN_Monetary"),white.adjust = "hc0")
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal+df$CN_Monetary)
summary(mod1)
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal)
summary(mod1)
df
df$China.News.Based.EPU
c(0,df$China.News.Based.EPU)
length(df)
dim(df)
c(0,df$China.News.Based.EPU)[1:28]
lag_1_epu = c(0,df$China.News.Based.EPU)[1:28]
df$lag_1_epu = lag_1_epu
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$CNEPU+df$CN_Fiscal+df$lag_1_epu)
summary(mod1)
linearHypothesis(mod1,c("df$CNEPU","df$CN_Fiscal"),white.adjust = "hc0")
mod1 = lm(df$close.1~df$China.News.Based.EPU+df$lag_1_epu)
summary(mod1)
