{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nlp_preprocess import NLP_Preprocess, BOW_Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_preprocess(text):\n",
    "    \n",
    "    word_cut = jieba.cut(text,HMM=True,use_paddle=True,cut_all=False)\n",
    "    \n",
    "    word_list = list(word_cut)\n",
    "    \n",
    "    pre_processor = NLP_Preprocess(word_list)\n",
    "    \n",
    "    pre_processor.remove_punc()\n",
    "    pre_processor.remove_number()\n",
    "    pre_processor.remove_single_character()\n",
    "    pre_processor.remove_stopwords(stopword_list=stopwords_list)\n",
    "    \n",
    "    return pre_processor.updated_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "file = \"content.csv\"\n",
    "\n",
    "df = pd.read_csv(data_directory+file)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "text = list(df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_directory = \"data/stopwords/\"\n",
    "file_1 = \"aggregate_stopwords.txt\"\n",
    "\n",
    "with open(stopwords_directory+file_1,\"r\",encoding=\"utf-8\") as f:\n",
    "    \n",
    "    stopwords_list = f.readlines()\n",
    "    stopwords_list = [word.strip() for word in stopwords_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Sunny\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.508 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "text_after_preprocess = []\n",
    "\n",
    "for one_text in text:\n",
    "    \n",
    "    if one_text != one_text:\n",
    "        \n",
    "        word_list = []\n",
    "        text_after_preprocess.append(word_list)\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    word_list = aggregate_preprocess(one_text)\n",
    "    text_after_preprocess.append(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_after_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_filter = BOW_Filter(text_after_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out Low frequency and high frequent word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_low_bound = 2\n",
    "\n",
    "df_low_bound = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_list,high_list = frequency_filter.document_frequency_filter(lower_bound = df_low_bound)\n",
    "low_list,high_list = frequency_filter.term_frequency_filter(lower_bound = wf_low_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_word_list = frequency_filter.show_filter_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_filter.manually_add_filter_words([\"中国\",\"总理\",\"李克强\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_filter.update_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8826"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = frequency_filter.dictionary\n",
    "len(dictionary.token2id.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_bow = [dictionary.doc2bow(one_word_list) for one_word_list in text_after_preprocess]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = TfidfModel(word_embedding_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_tf_idf = [tf_idf_model[one_bow] for one_bow in word_embedding_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast Text Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Skip For now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = word_embedding_bow\n",
    "dictionary = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=word_embedding,\n",
    "                id2word=dictionary,\n",
    "                num_topics=5,\n",
    "                random_state=100,\n",
    "                # update_every=1,\n",
    "                chunksize=1,\n",
    "                passes=20,\n",
    "                alpha='auto',\n",
    "                eta=\"auto\"\n",
    "                # per_word_topics=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.055*\"合作\" + 0.027*\"关系\" + 0.022*\"领域\" + 0.020*\"中方\" + 0.017*\"加强\" + 0.017*\"地区\" '\n",
      "  '+ 0.013*\"旅游\" + 0.013*\"和平\" + 0.011*\"国家\" + 0.010*\"宗教\" + 0.009*\"愿同\" + '\n",
      "  '0.009*\"政治\" + 0.009*\"交流\" + 0.009*\"国务院\" + 0.008*\"两国\" + 0.008*\"建设\" + '\n",
      "  '0.008*\"下午\" + 0.008*\"会见\" + 0.007*\"深化\" + 0.007*\"维护\"'),\n",
      " (1,\n",
      "  '0.022*\"监管\" + 0.021*\"部门\" + 0.018*\"管理\" + 0.013*\"制度\" + 0.013*\"行政\" + '\n",
      "  '0.012*\"国务院\" + 0.012*\"健康\" + 0.011*\"强化\" + 0.010*\"完善\" + 0.010*\"责任\" + '\n",
      "  '0.010*\"信息\" + 0.009*\"部署\" + 0.008*\"规定\" + 0.008*\"公开\" + 0.008*\"中央\" + 0.008*\"单位\" '\n",
      "  '+ 0.008*\"宗教\" + 0.007*\"依法\" + 0.007*\"取消\" + 0.007*\"政务\"'),\n",
      " (2,\n",
      "  '0.085*\"经济\" + 0.030*\"世界\" + 0.016*\"希望\" + 0.014*\"增长\" + 0.011*\"传统\" + 0.010*\"稳定\" '\n",
      "  '+ 0.010*\"金融\" + 0.009*\"形势\" + 0.009*\"战略\" + 0.008*\"贸易\" + 0.008*\"国际\" + '\n",
      "  '0.008*\"拓展\" + 0.007*\"开放\" + 0.007*\"代表\" + 0.007*\"创新\" + 0.007*\"各国\" + 0.006*\"指数\" '\n",
      "  '+ 0.006*\"复苏\" + 0.006*\"升级\" + 0.006*\"优势\"'),\n",
      " (3,\n",
      "  '0.031*\"创新\" + 0.029*\"就业\" + 0.016*\"创业\" + 0.015*\"考察\" + 0.011*\"建设\" + 0.010*\"教育\" '\n",
      "  '+ 0.009*\"群众\" + 0.008*\"鼓励\" + 0.008*\"国家\" + 0.008*\"双创\" + 0.008*\"成都\" + '\n",
      "  '0.008*\"制造\" + 0.007*\"技术\" + 0.007*\"精神\" + 0.007*\"社会主义\" + 0.007*\"学生\" + '\n",
      "  '0.007*\"创客\" + 0.007*\"互联网\" + 0.006*\"高校\" + 0.006*\"大众\"'),\n",
      " (4,\n",
      "  '0.068*\"发展\" + 0.025*\"企业\" + 0.022*\"改革\" + 0.020*\"推动\" + 0.019*\"推进\" + 0.015*\"会议\" '\n",
      "  '+ 0.013*\"促进\" + 0.013*\"政府\" + 0.013*\"投资\" + 0.013*\"支持\" + 0.012*\"市场\" + '\n",
      "  '0.011*\"政策\" + 0.011*\"实现\" + 0.010*\"社会\" + 0.009*\"服务\" + 0.009*\"重要\" + 0.009*\"发挥\" '\n",
      "  '+ 0.008*\"扩大\" + 0.008*\"提供\" + 0.008*\"负责人\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics(num_words=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = []\n",
    "model_list = []\n",
    "\n",
    "for num_topics in range(2,41,2):\n",
    "    \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                    id2word=id2word,\n",
    "                    num_topics=num_topics,\n",
    "                    # random_state=100,\n",
    "                    # update_every=1,\n",
    "                    # chunksize=100,\n",
    "                    # passes=10,\n",
    "                    # alpha='auto',\n",
    "                    # per_word_topics=True\n",
    "                                               )\n",
    "                                                \n",
    "    model_list.append(lda_model)\n",
    "    coherencemodel = CoherenceModel(model=lda_model, texts=text_after_preprocess, dictionary=id2word, coherence='c_v')\n",
    "    coherence_values.append(round(coherencemodel.get_coherence(),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(2,41,2)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = model_list[2]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num),                 round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    # print(contents)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    # print(sent_topics_df)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=text_after_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1 = df_topic_sents_keywords[df_topic_sents_keywords[\"Dominant_Topic\"]==5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_text = list(topic_1.sort_values(\"Perc_Contribution\",ascending=False)[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
